# ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Thai OCR ‡∏ö‡∏ô AWS SageMaker

## üìã ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

1. [‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ](#‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ)
2. [‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏£‡∏∞‡∏ö‡∏ö](#‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏£‡∏∞‡∏ö‡∏ö)
3. [‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Dataset](#‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°-dataset)
4. [‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Configuration](#‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤-configuration)
5. [‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Docker Container](#‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á-docker-container)
6. [‡∏Å‡∏≤‡∏£ Deploy ‡∏ö‡∏ô SageMaker](#‡∏Å‡∏≤‡∏£-deploy-‡∏ö‡∏ô-sagemaker)
7. [‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞ Monitor](#‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞-monitor)
8. [‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞ Performance](#‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞-performance)
9. [‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤](#‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤)
10. [‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á](#‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)

---

## üéØ ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ

### ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå
‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏°‡∏∏‡πà‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö **Thai OCR (Optical Character Recognition)** ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **PaddleOCR framework** ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö **AWS SageMaker** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ training ‡πÅ‡∏•‡∏∞ deployment

### ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏´‡∏•‡∏±‡∏Å
- **Framework**: PaddleOCR (Baidu's OCR toolkit)
- **Algorithm**: CRNN (Convolutional Recurrent Neural Network) + MobileNetV3
- **Cloud Platform**: AWS SageMaker
- **Container**: Docker + ECR
- **Infrastructure**: Terraform (Infrastructure as Code)
- **Language**: Python 3.9

### ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
- **Single Character Mode**: ‡∏£‡∏π‡πâ‡∏à‡∏≥‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ï‡πà‡∏≠‡∏£‡∏π‡∏õ
- **Fixed Input Size**: ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô 64x256 pixels
- **Accuracy**: ‡∏¢‡∏±‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô < 50%)

---

## üèóÔ∏è ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏£‡∏∞‡∏ö‡∏ö

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£ Training

```mermaid
graph TD
    A[Dataset Generation] --> B[PaddleOCR Conversion]
    B --> C[Upload to S3]
    C --> D[Docker Container Build]
    D --> E[ECR Push]
    E --> F[SageMaker Training Job]
    F --> G[Model Artifacts]
    G --> H[S3 Storage]
    H --> I[Model Deployment]
```

### ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á AWS Resources

| Resource | Purpose | Configuration |
|----------|---------|---------------|
| **S3 Bucket** | Data & Model Storage | `paddleocr-dev-data-bucket` |
| **ECR Repository** | Docker Images | `paddleocr-dev` |
| **SageMaker Training** | Model Training | `ml.g4dn.xlarge` (GPU) |
| **IAM Roles** | Permissions | `paddleocr-dev-sagemaker-role` |
| **CloudWatch** | Monitoring & Logs | Training metrics |

### Model Architecture

```yaml
Architecture:
  model_type: rec                    # Recognition model
  algorithm: CRNN                    # Convolutional Recurrent NN
  Backbone:
    name: MobileNetV3                # Lightweight CNN
    scale: 0.5                       # Model compression
    model_name: large                # MobileNetV3-Large variant
  Neck:
    name: SequenceEncoder            # Sequence processing
    encoder_type: rnn                # RNN encoder
    hidden_size: 96                  # Hidden layer size
  Head:
    name: CTCHead                    # CTC (Connectionist Temporal Classification)
    fc_decay: 0.00001               # Fully connected decay
```

---

## üìä ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Dataset

### 1. ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Synthetic Dataset

‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå `thai-letters/quick_phase1_generator.py` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏±‡∏á‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:

```bash
# ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå thai-letters
cd thai-letters

# ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏Ç‡∏ô‡∏≤‡∏î 10,000 ‡∏£‡∏π‡∏õ
python quick_phase1_generator.py 10

# ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: thai_dataset_YYYYMMDD_HHMMSS/
```

### 2. ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Dictionary

| Dictionary File | ‡∏Ç‡∏ô‡∏≤‡∏î | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ | Use Case |
|----------------|------|---------------|----------|
| `th_dict.txt` | 7,323 bytes | 880 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ | Full training |
| `number_dict.txt` | 20 bytes | 10 ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç | Numbers only |
| `minimal_dict.txt` | 150 bytes | 60 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ | Basic Thai |

### 3. Data Augmentation Effects

‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á 8 ‡πÄ‡∏≠‡∏ü‡πÄ‡∏ü‡∏Ñ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢:

```python
OCR_EFFECTS = {
    1: "rotation",      # ‡∏Å‡∏≤‡∏£‡∏´‡∏°‡∏∏‡∏ô ¬±15 ‡∏≠‡∏á‡∏®‡∏≤
    2: "brightness",    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á ¬±30%
    3: "contrast",      # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°‡∏ä‡∏±‡∏î ¬±20%
    4: "blur",          # ‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏•‡∏≠ (Gaussian)
    5: "noise",         # ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏£‡∏ö‡∏Å‡∏ß‡∏ô
    6: "position",      # ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
    7: "padding",       # ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ç‡∏≠‡∏ö
    8: "compression"    # ‡∏Å‡∏≤‡∏£‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î JPEG
}
```

### 4. ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô PaddleOCR Format

```bash
# ‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà PaddleOCR ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
python phase1_paddleocr_converter.py --input-path thai_dataset_20250807_120000 --output-path train_data_thai_paddleocr_v1

# ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå:
train_data_thai_paddleocr_v1/
‚îú‚îÄ‚îÄ rec/
‚îÇ   ‚îú‚îÄ‚îÄ rec_gt_train.txt      # Training labels (80%)
‚îÇ   ‚îú‚îÄ‚îÄ rec_gt_val.txt        # Validation labels (20%)
‚îÇ   ‚îî‚îÄ‚îÄ images/               # ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
‚îÇ       ‚îú‚îÄ‚îÄ 000_00.jpg
‚îÇ       ‚îú‚îÄ‚îÄ 001_01.jpg
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ th_dict.txt               # Character dictionary
```

### 5. ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Label Files

```bash
# ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏ô rec_gt_train.txt ‡πÅ‡∏•‡∏∞ rec_gt_val.txt
images/000_00.jpg	‡∏Å
images/001_01.jpg	‡∏Ç
images/002_02.jpg	‡∏Ñ
images/003_03.jpg	‡∏á
```

### 6. ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏∂‡πâ‡∏ô S3

```bash
# ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î dataset ‡∏Ç‡∏∂‡πâ‡∏ô AWS S3
aws s3 cp train_data_thai_paddleocr_v1/ s3://paddleocr-dev-data-bucket/data/training/ --recursive

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
aws s3 ls s3://paddleocr-dev-data-bucket/data/training/rec/ --human-readable
```

---

## ‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Configuration

### 1. ‡πÑ‡∏ü‡∏•‡πå Configuration ‡∏´‡∏•‡∏±‡∏Å

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `configs/rec/quick_single_char_config.yml`:

```yaml
Global:
  use_gpu: false                    # CPU training ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SageMaker
  distributed: false               # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ distributed training
  epoch_num: 100                   # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epochs
  log_smooth_window: 20            # ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£ log
  print_batch_step: 10             # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏∏‡∏Å 10 batch
  save_model_dir: ./output/thai_rec/  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å model
  save_epoch_step: 10              # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å checkpoint ‡∏ó‡∏∏‡∏Å 10 epoch
  eval_batch_step: 500             # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ó‡∏∏‡∏Å 500 batch
  cal_metric_during_train: true    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á training
  
  # Thai-specific settings
  character_dict_path: th_dict.txt # Dictionary ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
  character_type: thai             # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏†‡∏≤‡∏©‡∏≤
  max_text_length: 1              # ‡∏£‡∏π‡πâ‡∏à‡∏≥ 1 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ï‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á
  infer_mode: false               # ‡πÇ‡∏´‡∏°‡∏î training
  use_space_char: false           # ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ space character

Architecture:
  model_type: rec
  algorithm: CRNN
  Backbone:
    name: MobileNetV3
    scale: 0.5                     # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î model ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 50%
    model_name: large              # ‡πÉ‡∏ä‡πâ MobileNetV3-Large
  Neck:
    name: SequenceEncoder
    encoder_type: rnn              # RNN encoder
    hidden_size: 96                # ‡∏Ç‡∏ô‡∏≤‡∏î hidden layer
  Head:
    name: CTCHead                  # CTC head
    fc_decay: 0.00001             # Weight decay

Loss:
  name: CTCLoss                    # CTC Loss function

PostProcess:
  name: CTCLabelDecode             # CTC decoder

Optimizer:
  name: Adam                       # Adam optimizer
  beta1: 0.9
  beta2: 0.999
  lr:
    name: Cosine                   # Cosine learning rate schedule
    learning_rate: 0.001           # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà 0.001
    warmup_epoch: 5               # Warm-up 5 epochs

Train:
  dataset:
    name: SimpleDataSet
    data_dir: /opt/ml/input/data/training/rec/  # SageMaker path
    label_file_list:
      - /opt/ml/input/data/training/rec/rec_gt_train.txt
    transforms:
      - DecodeImage: {img_mode: BGR, channel_first: false}
      - CTCLabelEncode: {}
      - RecResizeImg: {image_shape: [3, 64, 256]}  # Resize ‡πÄ‡∏õ‡πá‡∏ô 64x256
      - KeepKeys: {keep_keys: ['image', 'label', 'length']}
  loader:
    shuffle: true                  # ‡∏™‡∏•‡∏±‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    batch_size_per_card: 256      # Batch size
    drop_last: false
    num_workers: 4                # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô worker processes

Eval:
  dataset:
    name: SimpleDataSet
    data_dir: /opt/ml/input/data/training/rec/
    label_file_list:
      - /opt/ml/input/data/training/rec/rec_gt_val.txt
    transforms:
      - DecodeImage: {img_mode: BGR, channel_first: false}
      - CTCLabelEncode: {}
      - RecResizeImg: {image_shape: [3, 64, 256]}
      - KeepKeys: {keep_keys: ['image', 'label', 'length']}
  loader:
    shuffle: false
    drop_last: false
    batch_size_per_card: 256
    num_workers: 4

Metric:
  name: RecMetric                  # Recognition metrics
  main_indicator: acc              # ‡∏´‡∏•‡∏±‡∏Å indicator ‡∏Ñ‡∏∑‡∏≠ accuracy
```

### 2. Environment-specific Configurations

| Config File | Epochs | Batch Size | Use Case |
|-------------|--------|------------|----------|
| `thai_rec_dev.yml` | 10 | 128 | Development/Testing |
| `thai_rec.yml` | 100 | 256 | Standard Training |
| `thai_rec_prod.yml` | 200 | 256 | Production Training |

---

## üê≥ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Docker Container

### 1. Dockerfile.sagemaker

```dockerfile
FROM python:3.9-slim

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á system dependencies
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    wget \
    git \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /opt/ml/code

# Copy ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Python dependencies
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PaddleOCR
RUN pip install --no-cache-dir paddlepaddle paddleocr

# Copy source code
COPY PaddleOCR/ ./PaddleOCR/
COPY configs/ ./configs/
COPY scripts/training/sagemaker_train.py ./

# Set environment variables
ENV PYTHONPATH=/opt/ml/code
ENV PYTHONUNBUFFERED=TRUE
ENV PYTHONDONTWRITEBYTECODE=TRUE

# Entry point ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SageMaker
ENTRYPOINT ["python", "sagemaker_train.py"]
```

### 2. Requirements.txt

```txt
# Core dependencies
numpy>=1.21.0
opencv-python>=4.5.0
Pillow>=8.3.0
scipy>=1.7.0

# Image processing
scikit-image>=0.19.0
imageio>=2.9.0

# Text processing
rapidfuzz>=2.0.0

# Machine Learning
scikit-learn>=1.0.0

# AWS SDK
boto3>=1.24.0
botocore>=1.27.0

# Utilities
tqdm>=4.62.0
pyyaml>=6.0
requests>=2.28.0
```

### 3. ‡∏Å‡∏≤‡∏£ Build ‡πÅ‡∏•‡∏∞ Push Docker Image

```bash
# Build Docker image
docker build -f Dockerfile.sagemaker -t thai-ocr-sagemaker .

# Tag ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ECR
docker tag thai-ocr-sagemaker:latest 484468818942.dkr.ecr.ap-southeast-1.amazonaws.com/paddleocr-dev:latest

# Login ‡πÄ‡∏Ç‡πâ‡∏≤ ECR
aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin 484468818942.dkr.ecr.ap-southeast-1.amazonaws.com

# Push ‡∏Ç‡∏∂‡πâ‡∏ô ECR
docker push 484468818942.dkr.ecr.ap-southeast-1.amazonaws.com/paddleocr-dev:latest
```

---

## üöÄ ‡∏Å‡∏≤‡∏£ Deploy ‡∏ö‡∏ô SageMaker

### 1. ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Automated Script

```bash
# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î - ‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
python scripts/continue_deployment_v2.py
```

‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
1. ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö AWS permissions
2. üèóÔ∏è Build Docker container
3. üì§ Push image ‡∏Ç‡∏∂‡πâ‡∏ô ECR
4. üìä Upload dataset ‡∏Ç‡∏∂‡πâ‡∏ô S3 (‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
5. üéØ ‡∏™‡∏£‡πâ‡∏≤‡∏á SageMaker training job
6. üìä Monitor ‡∏Å‡∏≤‡∏£ training

### 2. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Manual

#### ‡∏™‡∏£‡πâ‡∏≤‡∏á SageMaker Training Job ‡∏î‡πâ‡∏ß‡∏¢ Python:

```python
import boto3
from datetime import datetime

# ‡∏™‡∏£‡πâ‡∏≤‡∏á SageMaker client
sagemaker = boto3.client('sagemaker', region_name='ap-southeast-1')

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ training job
job_name = f'paddleocr-thai-training-{datetime.now().strftime("%Y%m%d-%H%M%S")}'

training_params = {
    'TrainingJobName': job_name,
    'AlgorithmSpecification': {
        'TrainingImage': '484468818942.dkr.ecr.ap-southeast-1.amazonaws.com/paddleocr-dev:latest',
        'TrainingInputMode': 'File'
    },
    'RoleArn': 'arn:aws:iam::484468818942:role/paddleocr-dev-sagemaker-role',
    'InputDataConfig': [
        {
            'ChannelName': 'training',
            'DataSource': {
                'S3DataSource': {
                    'S3DataType': 'S3Prefix',
                    'S3Uri': 's3://paddleocr-dev-data-bucket/data/training/',
                    'S3DataDistributionType': 'FullyReplicated'
                }
            }
        }
    ],
    'OutputDataConfig': {
        'S3OutputPath': 's3://paddleocr-dev-data-bucket/models/'
    },
    'ResourceConfig': {
        'InstanceType': 'ml.g4dn.xlarge',      # GPU instance
        'InstanceCount': 1,
        'VolumeSizeInGB': 30
    },
    'StoppingCondition': {
        'MaxRuntimeInSeconds': 259200           # 72 hours max
    },
    'HyperParameters': {
        'epochs': '100',
        'learning_rate': '0.001',
        'batch_size': '256'
    },
    'Tags': [
        {
            'Key': 'Project',
            'Value': 'thai-ocr'
        },
        {
            'Key': 'Environment',
            'Value': 'development'
        }
    ]
}

# ‡∏™‡∏£‡πâ‡∏≤‡∏á training job
response = sagemaker.create_training_job(**training_params)
print(f"Training job created: {job_name}")
```

### 3. SageMaker Training Script

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `scripts/training/sagemaker_train.py`:

```python
#!/usr/bin/env python3
import os
import sys
import json
import argparse
import subprocess
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def main():
    parser = argparse.ArgumentParser()
    
    # SageMaker specific arguments
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--learning_rate', type=float, default=0.001)
    parser.add_argument('--batch_size', type=int, default=256)
    
    args = parser.parse_args()
    
    # SageMaker environment paths
    input_path = '/opt/ml/input/data/training'
    output_path = '/opt/ml/output'
    model_path = '/opt/ml/model'
    
    logger.info(f"Training data path: {input_path}")
    logger.info(f"Model output path: {model_path}")
    
    # Verify input data
    if not os.path.exists(f"{input_path}/rec"):
        raise FileNotFoundError(f"Training data not found at {input_path}/rec")
    
    # List input files for debugging
    logger.info("Input files:")
    for root, dirs, files in os.walk(input_path):
        for file in files:
            logger.info(f"  {os.path.join(root, file)}")
    
    # Run PaddleOCR training
    cmd = [
        'python', 'PaddleOCR/tools/train.py',
        '-c', 'configs/rec/quick_single_char_config.yml',
        '-o', f'Global.epoch_num={args.epochs}',
        '-o', f'Optimizer.lr.learning_rate={args.learning_rate}',
        '-o', f'Train.loader.batch_size_per_card={args.batch_size}',
        '-o', f'Global.save_model_dir={model_path}/'
    ]
    
    logger.info(f"Running command: {' '.join(cmd)}")
    
    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        logger.info("Training completed successfully")
        logger.info(f"Output: {result.stdout}")
    except subprocess.CalledProcessError as e:
        logger.error(f"Training failed: {e}")
        logger.error(f"Error output: {e.stderr}")
        sys.exit(1)
    
    # Copy model files to output directory
    if os.path.exists(f"{model_path}/best_accuracy.pdparams"):
        logger.info("Model training completed successfully")
    else:
        logger.error("Model file not found after training")
        sys.exit(1)

if __name__ == '__main__':
    main()
```

---

## üìä ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞ Monitor

### 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Training Job

```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
aws sagemaker describe-training-job --training-job-name paddleocr-thai-training-20250807-120000

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö real-time
watch -n 30 'aws sagemaker describe-training-job --training-job-name paddleocr-thai-training-20250807-120000 --query "{Status: TrainingJobStatus, Secondary: SecondaryStatus, Time: TrainingTimeInSeconds}"'
```

### 2. ‡∏Å‡∏≤‡∏£‡∏î‡∏π CloudWatch Logs

```bash
# ‡∏î‡∏π logs ‡πÅ‡∏ö‡∏ö real-time
aws logs tail /aws/sagemaker/TrainingJobs --follow --log-stream-name-prefix paddleocr-thai-training

# ‡∏î‡∏π logs ‡∏à‡∏≤‡∏Å specific log stream
aws logs get-log-events \
  --log-group-name /aws/sagemaker/TrainingJobs \
  --log-stream-name paddleocr-thai-training-20250807-120000/algo-1-1691395200 \
  --start-time 1691395200000
```

### 3. Monitoring Script

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `scripts/utils/monitor_training.py`:

```python
import boto3
import time
import json
from datetime import datetime

class SageMakerMonitor:
    def __init__(self, job_name, region='ap-southeast-1'):
        self.job_name = job_name
        self.sagemaker = boto3.client('sagemaker', region_name=region)
        self.logs = boto3.client('logs', region_name=region)
    
    def get_training_status(self):
        """‡∏î‡∏π‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ç‡∏≠‡∏á training job"""
        try:
            response = self.sagemaker.describe_training_job(
                TrainingJobName=self.job_name
            )
            return {
                'status': response['TrainingJobStatus'],
                'secondary_status': response['SecondaryStatus'],
                'training_time': response.get('TrainingTimeInSeconds', 0),
                'billable_time': response.get('BillableTimeInSeconds', 0)
            }
        except Exception as e:
            return {'error': str(e)}
    
    def monitor_continuously(self, interval=60):
        """‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£ training ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á"""
        print(f"üéØ Monitoring training job: {self.job_name}")
        print("=" * 60)
        
        while True:
            status = self.get_training_status()
            
            if 'error' in status:
                print(f"‚ùå Error: {status['error']}")
                break
            
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            print(f"[{timestamp}] Status: {status['status']} | "
                  f"Secondary: {status['secondary_status']} | "
                  f"Time: {status['training_time']}s")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ training ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
            if status['status'] in ['Completed', 'Failed', 'Stopped']:
                print(f"üèÅ Training {status['status'].lower()}")
                print(f"‚è±Ô∏è Total training time: {status['training_time']} seconds")
                print(f"üí∞ Billable time: {status['billable_time']} seconds")
                break
            
            time.sleep(interval)

# ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
if __name__ == '__main__':
    import sys
    if len(sys.argv) != 2:
        print("Usage: python monitor_training.py <training-job-name>")
        sys.exit(1)
    
    monitor = SageMakerMonitor(sys.argv[1])
    monitor.monitor_continuously()
```

### 4. ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Metrics

```python
import boto3
import matplotlib.pyplot as plt

def get_training_metrics(job_name):
    """‡∏î‡∏∂‡∏á metrics ‡∏à‡∏≤‡∏Å CloudWatch"""
    cloudwatch = boto3.client('cloudwatch')
    
    metrics = cloudwatch.get_metric_statistics(
        Namespace='AWS/SageMaker',
        MetricName='TrainingJobStatus',
        Dimensions=[
            {
                'Name': 'TrainingJobName',
                'Value': job_name
            }
        ],
        StartTime=datetime(2025, 8, 7),
        EndTime=datetime.now(),
        Period=300,
        Statistics=['Average']
    )
    
    return metrics['Datapoints']

# Plot training progress
def plot_training_progress(job_name):
    metrics = get_training_metrics(job_name)
    
    plt.figure(figsize=(10, 6))
    timestamps = [point['Timestamp'] for point in metrics]
    values = [point['Average'] for point in metrics]
    
    plt.plot(timestamps, values)
    plt.title(f'Training Progress: {job_name}')
    plt.xlabel('Time')
    plt.ylabel('Status')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
```

---

## üìà ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏•‡∏∞ Performance

### 1. ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£ Training

| Metric | Value | Description |
|--------|-------|-------------|
| **Instance Type** | ml.g4dn.xlarge | GPU instance (Tesla T4) |
| **Training Duration** | 25+ ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á | 1 ‡∏ß‡∏±‡∏ô 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á 17 ‡∏ô‡∏≤‡∏ó‡∏µ |
| **Dataset Size** | 9,408 ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û | Synthetic Thai characters |
| **Model Size** | 9.2 MB | `best_accuracy.pdparams` |
| **Total Cost** | ~$25 USD | AWS SageMaker training cost |
| **Epochs Completed** | 100/100 | Full training completed |

### 2. Model Performance

#### ‚úÖ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ:
- **Model Loading**: 100% ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
- **Inference Execution**: 93.3% ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (14/15 samples)
- **Single Character Output**: ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
- **Configuration Compatibility**: Training config ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö inference config

#### ‚ùå ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö:
- **Character Accuracy**: ‡∏ï‡πà‡∏≥‡∏°‡∏≤‡∏Å (< 50%)
- **Character Recognition**: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö ground truth

### 3. ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

```python
# Test Results (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå test_images/)
test_results = {
    'thai_word_01_‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ.jpg': {
        'ground_truth': '‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ',
        'predicted': '‡∏™',
        'accuracy': False
    },
    'thai_word_02_‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì.jpg': {
        'ground_truth': '‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì',
        'predicted': '‡∏Ç',
        'accuracy': False
    },
    'thai_word_03_‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢.jpg': {
        'ground_truth': '‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢',
        'predicted': '‡∏õ',
        'accuracy': False
    }
}
```

### 4. Model Files ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ

```bash
# ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå model ‡∏ó‡∏µ‡πà training ‡πÄ‡∏™‡∏£‡πá‡∏à
models/sagemaker_trained/
‚îú‚îÄ‚îÄ best_accuracy.pdparams      # Model parameters (9,205,880 bytes)
‚îú‚îÄ‚îÄ best_accuracy.pdopt         # Optimizer state
‚îú‚îÄ‚îÄ config.yml                  # Training configuration (2,262 bytes)
‚îú‚îÄ‚îÄ train.log                   # Training logs
‚îî‚îÄ‚îÄ iter_epoch_*.pdparams       # Checkpoint files
```

### 5. Training Logs Summary

```
Key Training Metrics:
- Learning Rate: Started at 0.001, decayed with Cosine schedule
- Batch Size: 256 samples per batch
- Loss Function: CTC Loss (Connectionist Temporal Classification)
- Optimizer: Adam (beta1=0.9, beta2=0.999)
- Validation: Performed every 500 batches
- Checkpoints: Saved every 10 epochs
```

---

## üîß ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤

### 1. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Docker ‡πÅ‡∏•‡∏∞ Dependencies

#### ‚ùå Error: `ModuleNotFoundError: No module named 'skimage'`
```bash
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô requirements.txt
scikit-image>=0.19.0
```

#### ‚ùå Error: `ImportError: libGL.so.1: cannot open shared object file`
```dockerfile
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô Dockerfile
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libgomp1
```

#### ‚ùå Error: `ModuleNotFoundError: No module named 'rapidfuzz'`
```bash
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô requirements.txt
rapidfuzz>=2.0.0
```

### 2. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Configuration ‡πÅ‡∏•‡∏∞ Data

#### ‚ùå Error: `FileNotFoundError: rec_gt_train.txt`
```yaml
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡πÉ‡∏ô config
Train:
  dataset:
    data_dir: /opt/ml/input/data/training/rec/  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ trailing slash
    label_file_list:
      - /opt/ml/input/data/training/rec/rec_gt_train.txt
```

#### ‚ùå Error: `AttributeError: 'NoneType' object has no attribute 'distributed'`
```yaml
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô Global config
Global:
  distributed: false    # ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SageMaker
```

### 3. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Memory ‡πÅ‡∏•‡∏∞ Performance

#### ‚ùå Out of Memory
```yaml
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏•‡∏î batch size
Train:
  loader:
    batch_size_per_card: 128    # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 256
Eval:
  loader:
    batch_size_per_card: 128
```

#### ‚ùå Training ‡∏ä‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
```yaml
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÄ‡∏û‡∏¥‡πà‡∏° num_workers
Train:
  loader:
    num_workers: 8      # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 4
```

### 4. ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ AWS ‡πÅ‡∏•‡∏∞ SageMaker

#### ‚ùå IAM Permission Denied
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö permissions
aws sts get-caller-identity
python test_aws_permissions.py
```

#### ‚ùå ECR Push ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
```bash
# Login ‡πÉ‡∏´‡∏°‡πà
aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin 484468818942.dkr.ecr.ap-southeast-1.amazonaws.com
```

### 5. Debug Scripts

#### ‡∏™‡∏£‡πâ‡∏≤‡∏á Debug Script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Environment:

```python
# scripts/utils/debug_environment.py
import os
import sys
import json

def debug_sagemaker_environment():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö SageMaker environment"""
    print("üîç SageMaker Environment Debug")
    print("=" * 50)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö paths
    paths_to_check = [
        '/opt/ml/input/data/training',
        '/opt/ml/output',
        '/opt/ml/model',
        '/opt/ml/code'
    ]
    
    for path in paths_to_check:
        if os.path.exists(path):
            print(f"‚úÖ {path} exists")
            if os.path.isdir(path):
                files = os.listdir(path)
                print(f"   üìÅ Contains {len(files)} items")
                for item in files[:5]:  # ‡πÅ‡∏™‡∏î‡∏á 5 items ‡πÅ‡∏£‡∏Å
                    print(f"   - {item}")
                if len(files) > 5:
                    print(f"   ... and {len(files) - 5} more")
        else:
            print(f"‚ùå {path} does not exist")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö environment variables
    env_vars = ['SM_MODEL_DIR', 'SM_OUTPUT_DIR', 'SM_CHANNEL_TRAINING']
    print("\nüåç Environment Variables:")
    for var in env_vars:
        value = os.environ.get(var, 'Not set')
        print(f"   {var}: {value}")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Python environment
    print(f"\nüêç Python Version: {sys.version}")
    print(f"üì¶ Python Path: {sys.executable}")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö installed packages
    try:
        import paddle
        print(f"üèÑ PaddlePaddle Version: {paddle.__version__}")
    except ImportError:
        print("‚ùå PaddlePaddle not installed")
    
    try:
        import cv2
        print(f"üëÅÔ∏è OpenCV Version: {cv2.__version__}")
    except ImportError:
        print("‚ùå OpenCV not installed")

if __name__ == '__main__':
    debug_sagemaker_environment()
```

---

## üöÄ ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á

### 1. ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Dataset Quality

#### ‡πÄ‡∏û‡∏¥‡πà‡∏° Real Data:
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° real Thai text images
import requests
import cv2
import numpy as np

class RealDataCollector:
    def __init__(self):
        self.sources = [
            'thai_newspapers',
            'government_documents', 
            'educational_materials',
            'handwritten_texts'
        ]
    
    def collect_real_images(self, count=1000):
        """‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏ó‡∏¢‡∏à‡∏£‡∏¥‡∏á"""
        # Implementation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
        pass
    
    def augment_real_data(self, images):
        """‡πÄ‡∏û‡∏¥‡πà‡∏° augmentation ‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á"""
        augmented = []
        for img in images:
            # Apply realistic augmentations
            augmented.extend([
                self.add_scanner_noise(img),
                self.simulate_photocopy(img),
                self.add_perspective_distortion(img),
                self.simulate_mobile_capture(img)
            ])
        return augmented
```

#### ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Character Dictionary:
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á optimized dictionary
def create_optimized_dictionary():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á dictionary ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö single character"""
    
    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÑ‡∏ó‡∏¢‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (44 ‡∏ï‡∏±‡∏ß)
    thai_consonants = [
        '‡∏Å', '‡∏Ç', '‡∏É', '‡∏Ñ', '‡∏Ö', '‡∏Ü', '‡∏á', '‡∏à', '‡∏â', '‡∏ä', '‡∏ã', '‡∏å', '‡∏ç',
        '‡∏é', '‡∏è', '‡∏ê', '‡∏ë', '‡∏í', '‡∏ì', '‡∏î', '‡∏ï', '‡∏ñ', '‡∏ó', '‡∏ò', '‡∏ô', '‡∏ö',
        '‡∏õ', '‡∏ú', '‡∏ù', '‡∏û', '‡∏ü', '‡∏†', '‡∏°', '‡∏¢', '‡∏£', '‡∏•', '‡∏ß', '‡∏®', '‡∏©',
        '‡∏™', '‡∏´', '‡∏¨', '‡∏≠', '‡∏Æ'
    ]
    
    # ‡∏™‡∏£‡∏∞‡πÅ‡∏•‡∏∞‡∏ß‡∏£‡∏£‡∏ì‡∏¢‡∏∏‡∏Å‡∏ï‡πå (18 ‡∏ï‡∏±‡∏ß)
    thai_vowels_marks = [
        '‡∏∞', '‡∏±', '‡∏≤', '‡∏≥', '‡∏¥', '‡∏µ', '‡∏∂', '‡∏∑', '‡∏∏', '‡∏π',
        '‡πà', '‡πâ', '‡πä', '‡πã', '‡πå', '‡πÜ', '‡∏Ø', '‡πè'
    ]
    
    # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (10 ‡∏ï‡∏±‡∏ß)
    numbers = ['‡πê', '‡πë', '‡πí', '‡πì', '‡πî', '‡πï', '‡πñ', '‡πó', '‡πò', '‡πô']
    
    # ‡∏£‡∏ß‡∏° 72 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (‡∏•‡∏î‡∏à‡∏≤‡∏Å 880)
    optimized_chars = thai_consonants + thai_vowels_marks + numbers
    
    return optimized_chars
```

### 2. ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î Model Architecture

#### ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô SVTR_LCNet (Modern Architecture):
```yaml
Architecture:
  model_type: rec
  algorithm: SVTR_LCNet              # ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î‡∏à‡∏≤‡∏Å CRNN
  Backbone:
    name: SVTRNet                    # State-of-the-art backbone
    img_size: [64, 256]
    out_char_num: 25
    out_channels: 192
    patch_merging: 'Conv'
    embed_dim: [64, 128, 256]
    depth: [3, 6, 3]
    num_heads: [2, 4, 8]
    mixer: ['Local'] * 6 + ['Global'] * 6
```

#### ‡πÄ‡∏û‡∏¥‡πà‡∏° Attention Mechanism:
```yaml
Neck:
  name: SequenceEncoder
  encoder_type: transformer          # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å RNN ‡πÄ‡∏õ‡πá‡∏ô Transformer
  hidden_size: 256                   # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î
  attention_heads: 8                 # Multi-head attention
```

### 3. ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Training Strategy

#### Curriculum Learning:
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á training curriculum
class CurriculumTraining:
    def __init__(self):
        self.stages = [
            {
                'name': 'simple_characters',
                'epochs': 50,
                'data': 'basic_thai_consonants',
                'difficulty': 'easy'
            },
            {
                'name': 'complex_characters', 
                'epochs': 50,
                'data': 'vowels_and_marks',
                'difficulty': 'medium'
            },
            {
                'name': 'mixed_training',
                'epochs': 100,
                'data': 'all_characters',
                'difficulty': 'hard'
            }
        ]
```

#### Transfer Learning:
```python
# ‡πÉ‡∏ä‡πâ pre-trained model
def setup_transfer_learning():
    """‡πÉ‡∏ä‡πâ model ‡∏ó‡∏µ‡πà train ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô"""
    config = {
        'Global': {
            'pretrained_model': 'path/to/pretrained/english_ocr_model.pdparams',
            'freeze_backbone': True,      # Freeze backbone layers
            'finetune_head_only': True    # Train ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ head
        }
    }
    return config
```

### 4. ‡πÄ‡∏û‡∏¥‡πà‡∏° Multi-Character Support

#### ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î Configuration:
```yaml
Global:
  max_text_length: 10               # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 1 ‡πÄ‡∏õ‡πá‡∏ô 10
  use_space_char: true              # Support space character

Train:
  dataset:
    transforms:
      - RecResizeImg: {image_shape: [3, 64, 512]}  # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á
```

#### ‡∏™‡∏£‡πâ‡∏≤‡∏á Multi-Character Dataset:
```python
def create_multichar_dataset():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£"""
    thai_words = [
        '‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ', '‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì', '‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢', '‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢',
        '‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤', '‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ', '‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå'
    ]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ
    for word in thai_words:
        create_word_image(word)
```

### 5. Production Deployment

#### SageMaker Endpoint:
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á real-time inference endpoint
import boto3

def deploy_to_endpoint():
    """Deploy model ‡πÄ‡∏õ‡πá‡∏ô SageMaker endpoint"""
    sagemaker = boto3.client('sagemaker')
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á model
    model_name = 'thai-ocr-production-model'
    sagemaker.create_model(
        ModelName=model_name,
        PrimaryContainer={
            'Image': '484468818942.dkr.ecr.ap-southeast-1.amazonaws.com/paddleocr-inference:latest',
            'ModelDataUrl': 's3://paddleocr-prod-bucket/models/best_model.tar.gz'
        },
        ExecutionRoleArn='arn:aws:iam::484468818942:role/paddleocr-prod-sagemaker-role'
    )
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á endpoint configuration
    endpoint_config_name = 'thai-ocr-endpoint-config'
    sagemaker.create_endpoint_config(
        EndpointConfigName=endpoint_config_name,
        ProductionVariants=[
            {
                'VariantName': 'primary',
                'ModelName': model_name,
                'InitialInstanceCount': 1,
                'InstanceType': 'ml.t2.medium',
                'InitialVariantWeight': 100
            }
        ]
    )
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á endpoint
    endpoint_name = 'thai-ocr-endpoint'
    sagemaker.create_endpoint(
        EndpointName=endpoint_name,
        EndpointConfigName=endpoint_config_name
    )
```

#### API Gateway Integration:
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á REST API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OCR service
def create_api_gateway():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á API Gateway ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OCR service"""
    return {
        'api_name': 'thai-ocr-api',
        'methods': ['POST'],
        'endpoints': {
            '/recognize': '‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏π‡πâ‡∏à‡∏≥‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£',
            '/health': '‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ service'
        },
        'authentication': 'API Key',
        'rate_limiting': '1000 requests/hour'
    }
```

---

## üìã Checklist ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production

### ‚úÖ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Data
- [ ] ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 10,000 ‡∏£‡∏π‡∏õ/‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
- [ ] ‡∏ó‡∏≥ data cleaning ‡πÅ‡∏•‡∏∞ quality assurance
- [ ] ‡∏™‡∏£‡πâ‡∏≤‡∏á balanced dataset (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)
- [ ] ‡πÅ‡∏ö‡πà‡∏á train/validation/test sets (70/15/15)

### ‚úÖ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Model
- [ ] ‡∏≠‡∏±‡∏õ‡πÄ‡∏Å‡∏£‡∏î‡πÄ‡∏õ‡πá‡∏ô SVTR_LCNet architecture
- [ ] ‡πÉ‡∏ä‡πâ optimized dictionary (72 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)
- [ ] Implement attention mechanism
- [ ] ‡πÄ‡∏û‡∏¥‡πà‡∏° multi-character support

### ‚úÖ ‡∏Å‡∏≤‡∏£ Training
- [ ] ‡πÉ‡∏ä‡πâ curriculum learning strategy
- [ ] Implement transfer learning
- [ ] ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ proper validation metrics
- [ ] ‡πÉ‡∏ä‡πâ early stopping ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting

### ‚úÖ ‡∏Å‡∏≤‡∏£ Deploy
- [ ] ‡∏™‡∏£‡πâ‡∏≤‡∏á production Docker container
- [ ] ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ SageMaker endpoint
- [ ] ‡∏™‡∏£‡πâ‡∏≤‡∏á API Gateway
- [ ] ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ monitoring ‡πÅ‡∏•‡∏∞ alerting

### ‚úÖ ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
- [ ] Unit tests ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å component
- [ ] Integration tests ‡∏Å‡∏±‡∏ö AWS services
- [ ] Performance testing ‡∏ö‡∏ô real data
- [ ] Load testing ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö API endpoint

---

## üìû ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÅ‡∏•‡∏∞‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Thai OCR ‡∏ö‡∏ô SageMaker:

- **Documentation**: `doc/` folder ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
- **Issues**: GitHub Issues ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö bug reports
- **Scripts**: `scripts/` folder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö automation tools
- **Configuration**: `configs/` folder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö model configs

---

## üìö ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

- [PaddleOCR Official Documentation](https://github.com/PaddlePaddle/PaddleOCR)
- [AWS SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [Terraform AWS Provider](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)

---

*‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Thai OCR ‡∏ö‡∏ô AWS SageMaker ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£ deploy ‡πÄ‡∏õ‡πá‡∏ô production service*
