#!/usr/bin/env python3
"""
Simple Image Test: à¸—à¸”à¸ªà¸­à¸šà¹‚à¸¡à¹€à¸”à¸¥à¹à¸šà¸šà¸‡à¹ˆà¸²à¸¢ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ CV2 à¸­à¹ˆà¸²à¸™à¸£à¸¹à¸›à¹à¸¥à¹‰à¸§à¹à¸ªà¸”à¸‡à¸œà¸¥
"""

import os
import cv2
import numpy as np
from pathlib import Path
import random
from typing import List, Tuple

def test_simple_image_reading():
    """à¸—à¸”à¸ªà¸­à¸šà¸à¸²à¸£à¸­à¹ˆà¸²à¸™à¸£à¸¹à¸›à¹à¸šà¸šà¸‡à¹ˆà¸²à¸¢"""
    
    project_root = Path(__file__).parent.parent.parent
    dataset_dir = project_root / "thai-letters" / "datasets" / "converted" / "train_data_thai_paddleocr_0731_1604"
    
    # à¸«à¸² validation images
    val_images_dir = dataset_dir / "train_data" / "rec" / "thai_data" / "val"
    val_labels_file = dataset_dir / "train_data" / "rec" / "rec_gt_val.txt"
    
    print("ğŸ” Simple Thai OCR Dataset Test")
    print("=" * 50)
    
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œ
    if not val_images_dir.exists():
        print(f"âŒ Validation images not found: {val_images_dir}")
        return
    
    if not val_labels_file.exists():
        print(f"âŒ Labels file not found: {val_labels_file}")
        return
    
    print(f"âœ… Dataset found: {dataset_dir.name}")
    print(f"ğŸ“ Images: {val_images_dir}")
    print(f"ğŸ“„ Labels: {val_labels_file}")
    
    # à¸­à¹ˆà¸²à¸™ labels
    labels = {}
    with open(val_labels_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if '\t' in line:
                img_path, text = line.split('\t', 1)
                full_path = dataset_dir / "train_data" / "rec" / img_path
                if full_path.exists():
                    labels[str(full_path)] = text.strip()
    
    print(f"ğŸ“Š Loaded {len(labels)} labels")
    
    # à¸ªà¸¸à¹ˆà¸¡à¹€à¸¥à¸·à¸­à¸ 10 à¸£à¸¹à¸›
    sample_items = random.sample(list(labels.items()), min(10, len(labels)))
    
    print(f"\nğŸ–¼ï¸ Sample Analysis (10 random images):")
    print("-" * 50)
    
    for i, (img_path, ground_truth) in enumerate(sample_items, 1):
        img_name = Path(img_path).name
        
        # à¸­à¹ˆà¸²à¸™à¸£à¸¹à¸›
        try:
            img = cv2.imread(img_path)
            if img is not None:
                h, w = img.shape[:2]
                print(f"{i:2d}. {img_name:<15} â†’ '{ground_truth:<10}' ({w}x{h}px)")
                
                # à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸à¸·à¹‰à¸™à¸à¸²à¸™
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                mean_brightness = np.mean(gray)
                std_brightness = np.std(gray)
                
                # à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸„à¸¸à¸“à¸ à¸²à¸à¸£à¸¹à¸›
                quality = "Good"
                if std_brightness < 20:
                    quality = "Low contrast"
                elif mean_brightness < 50:
                    quality = "Too dark"
                elif mean_brightness > 200:
                    quality = "Too bright"
                
                print(f"     Quality: {quality} (brightness: {mean_brightness:.0f}Â±{std_brightness:.0f})")
            else:
                print(f"{i:2d}. {img_name:<15} â†’ ERROR: Cannot read image")
                
        except Exception as e:
            print(f"{i:2d}. {img_name:<15} â†’ ERROR: {e}")
    
    # à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œ character distribution
    print(f"\nğŸ”¤ Character Analysis:")
    print("-" * 50)
    
    char_count = {}
    for text in labels.values():
        for char in text:
            char_count[char] = char_count.get(char, 0) + 1
    
    # à¹à¸ªà¸”à¸‡ top 20 characters
    top_chars = sorted(char_count.items(), key=lambda x: x[1], reverse=True)[:20]
    print("Top 20 most frequent characters:")
    for i, (char, count) in enumerate(top_chars, 1):
        print(f"  {i:2d}. '{char}': {count:3d} times")
    
    print(f"\nğŸ“ˆ Dataset Statistics:")
    print(f"   Total images: {len(labels)}")
    print(f"   Unique characters: {len(char_count)}")
    print(f"   Average text length: {np.mean([len(text) for text in labels.values()]):.1f}")
    
    print(f"\nâœ… Dataset analysis completed!")
    print(f"   This confirms our training data is properly formatted")
    print(f"   Next step: Test with actual OCR model inference")

def show_sample_images():
    """à¹à¸ªà¸”à¸‡à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸¹à¸›à¸ à¸²à¸"""
    
    project_root = Path(__file__).parent.parent.parent
    dataset_dir = project_root / "thai-letters" / "datasets" / "converted" / "train_data_thai_paddleocr_0731_1604"
    val_images_dir = dataset_dir / "train_data" / "rec" / "thai_data" / "val"
    val_labels_file = dataset_dir / "train_data" / "rec" / "rec_gt_val.txt"
    
    if not val_images_dir.exists() or not val_labels_file.exists():
        print("âŒ Dataset not found!")
        return
    
    # à¸­à¹ˆà¸²à¸™ labels
    labels = {}
    with open(val_labels_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if '\t' in line:
                img_path, text = line.split('\t', 1)
                full_path = dataset_dir / "train_data" / "rec" / img_path
                if full_path.exists():
                    labels[str(full_path)] = text.strip()
    
    # à¹€à¸¥à¸·à¸­à¸ 5 à¸£à¸¹à¸›
    sample_items = random.sample(list(labels.items()), 5)
    
    print("ğŸ–¼ï¸ Sample Images Preview:")
    print("=" * 40)
    
    for img_path, ground_truth in sample_items:
        img_name = Path(img_path).name
        print(f"\nğŸ“· {img_name}")
        print(f"   Text: '{ground_truth}'")
        
        # à¸­à¹ˆà¸²à¸™à¸£à¸¹à¸›
        img = cv2.imread(img_path)
        if img is not None:
            h, w = img.shape[:2]
            print(f"   Size: {w}Ã—{h} pixels")
            
            # Save a copy for inspection (optional)
            # cv2.imwrite(f"sample_{img_name}", img)
        else:
            print(f"   ERROR: Cannot read image")

if __name__ == "__main__":
    test_simple_image_reading()
    print("\n" + "="*50)
    show_sample_images()
