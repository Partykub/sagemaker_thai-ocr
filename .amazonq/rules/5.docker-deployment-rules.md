# Docker and Deployment Rules

## Docker Configuration Standards

### Multi-stage Dockerfile for Training
```dockerfile
# Training image with PaddleOCR
FROM python:3.8-slim as base

# Install system dependencies
RUN apt-get update && apt-get install -y \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    wget \
    git \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /opt/ml/code

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install PaddleOCR
RUN pip install paddlepaddle paddleocr

# Training stage
FROM base as training

# Copy training scripts and configs
COPY scripts/ scripts/
COPY configs/ configs/
COPY ppocr/ ppocr/
COPY th_dict.txt .

# Set environment variables
ENV PYTHONPATH=/opt/ml/code
ENV PADDLE_TRAINERS_NUM=1
ENV PADDLE_TRAINER_ID=0

# Entry point for SageMaker training
ENTRYPOINT ["python", "scripts/training/train.py"]

# Inference stage
FROM base as inference

# Copy inference scripts and model artifacts
COPY scripts/inference/ scripts/inference/
COPY models/ models/
COPY th_dict.txt .

# Expose port for inference server
EXPOSE 8080

# Entry point for inference
ENTRYPOINT ["python", "scripts/inference/serve.py"]
```

### Docker Compose for Local Development
```yaml
# docker-compose.yml for local development
version: '3.8'

services:
  thai-ocr-training:
    build:
      context: .
      target: training
    volumes:
      - ./train_data_thai_paddleocr_v1:/opt/ml/input/data/training
      - ./models:/opt/ml/model
      - ./logs:/opt/ml/output
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/opt/ml/code
    command: >
      python scripts/training/train.py
      --config configs/rec/thai_rec_config.yml
      --epochs 50

  thai-ocr-inference:
    build:
      context: .
      target: inference
    ports:
      - "8080:8080"
    volumes:
      - ./models:/opt/ml/model
    environment:
      - MODEL_PATH=/opt/ml/model/thai_rec_model
      - PYTHONPATH=/opt/ml/code
```

## SageMaker Deployment Patterns

### Training Script Structure
```python
# scripts/training/train.py
import argparse
import os
import sys
import logging
from pathlib import Path

# Add PaddleOCR to path
sys.path.append('/opt/ml/code')

import paddle
from ppocr.data import create_operators, transform
from ppocr.modeling.architectures import build_model
from ppocr.losses import build_loss
from ppocr.optimizer import build_optimizer
from ppocr.postprocess import build_post_process
from ppocr.metrics import build_metric
from ppocr.utils.save_load import load_model

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description='Thai OCR Training')
    parser.add_argument('--config', type=str, required=True, help='Config file path')
    parser.add_argument('--epochs', type=int, default=100, help='Number of epochs')
    parser.add_argument('--batch-size', type=int, default=32, help='Batch size')
    parser.add_argument('--learning-rate', type=float, default=0.001, help='Learning rate')
    
    # SageMaker specific arguments
    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR', '/opt/ml/model'))
    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAINING', '/opt/ml/input/data/training'))
    parser.add_argument('--output-dir', type=str, default=os.environ.get('SM_OUTPUT_DIR', '/opt/ml/output'))
    
    return parser.parse_args()

def setup_logging(output_dir: str):
    """Setup logging configuration."""
    log_file = Path(output_dir) / 'training.log'
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout)
        ]
    )

def main():
    """Main training function."""
    args = parse_args()
    setup_logging(args.output_dir)
    
    logger = logging.getLogger(__name__)
    logger.info(f"Starting Thai OCR training with config: {args.config}")
    
    # Load configuration
    config = load_config(args.config)
    
    # Override config with command line arguments
    config['Global']['epoch_num'] = args.epochs
    config['Train']['loader']['batch_size_per_card'] = args.batch_size
    config['Optimizer']['lr']['learning_rate'] = args.learning_rate
    
    # Set data paths
    config['Train']['dataset']['data_dir'] = args.train
    config['Eval']['dataset']['data_dir'] = args.train
    
    # Build model, loss, optimizer, etc.
    model = build_model(config['Architecture'])
    loss_class = build_loss(config['Loss'])
    optimizer = build_optimizer(config['Optimizer'], model.parameters())
    
    # Training loop
    train_model(model, loss_class, optimizer, config, args.model_dir)
    
    logger.info("Training completed successfully")

if __name__ == '__main__':
    main()
```

### Inference Script Structure
```python
# scripts/inference/serve.py
import json
import os
import sys
import logging
from pathlib import Path
from typing import Dict, Any

import paddle
import numpy as np
from PIL import Image
import cv2

# Add PaddleOCR to path
sys.path.append('/opt/ml/code')

from ppocr.modeling.architectures import build_model
from ppocr.postprocess import build_post_process
from ppocr.utils.save_load import load_model

class ThaiOCRPredictor:
    """Thai OCR model predictor for SageMaker inference."""
    
    def __init__(self, model_path: str):
        self.model_path = Path(model_path)
        self.model = None
        self.post_process = None
        self.load_model()
    
    def load_model(self):
        """Load trained model and post-processing components."""
        config_path = self.model_path / 'config.yml'
        model_path = self.model_path / 'model.pdparams'
        
        # Load configuration
        config = load_config(str(config_path))
        
        # Build model
        self.model = build_model(config['Architecture'])
        load_model(config, self.model, model_path=str(model_path))
        self.model.eval()
        
        # Build post-processor
        self.post_process = build_post_process(config['PostProcess'])
        
        logging.info("Model loaded successfully")
    
    def preprocess_image(self, image_data: bytes) -> np.ndarray:
        """Preprocess input image for inference."""
        # Convert bytes to PIL Image
        image = Image.open(io.BytesIO(image_data))
        
        # Convert to OpenCV format
        image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        
        # Resize to model input size
        image = cv2.resize(image, (256, 64))
        
        # Normalize
        image = image.astype(np.float32) / 255.0
        image = (image - 0.5) / 0.5
        
        # Add batch dimension
        image = np.expand_dims(image.transpose(2, 0, 1), axis=0)
        
        return image
    
    def predict(self, image_data: bytes) -> Dict[str, Any]:
        """Perform OCR prediction on input image."""
        try:
            # Preprocess image
            processed_image = self.preprocess_image(image_data)
            
            # Convert to Paddle tensor
            image_tensor = paddle.to_tensor(processed_image)
            
            # Inference
            with paddle.no_grad():
                predictions = self.model(image_tensor)
            
            # Post-process
            result = self.post_process(predictions)
            
            return {
                'text': result[0][0],
                'confidence': float(result[0][1]),
                'status': 'success'
            }
            
        except Exception as e:
            logging.error(f"Prediction error: {e}")
            return {
                'text': '',
                'confidence': 0.0,
                'status': 'error',
                'error': str(e)
            }

# SageMaker inference functions
def model_fn(model_dir: str):
    """Load model for SageMaker inference."""
    return ThaiOCRPredictor(model_dir)

def input_fn(request_body: bytes, content_type: str):
    """Parse input data for inference."""
    if content_type == 'application/x-image':
        return request_body
    elif content_type == 'application/json':
        data = json.loads(request_body)
        import base64
        return base64.b64decode(data['image'])
    else:
        raise ValueError(f"Unsupported content type: {content_type}")

def predict_fn(input_data: bytes, model: ThaiOCRPredictor):
    """Perform prediction."""
    return model.predict(input_data)

def output_fn(prediction: Dict[str, Any], accept: str):
    """Format output for response."""
    if accept == 'application/json':
        return json.dumps(prediction), accept
    else:
        raise ValueError(f"Unsupported accept type: {accept}")

# For local testing
if __name__ == '__main__':
    import io
    from flask import Flask, request, jsonify
    
    app = Flask(__name__)
    
    # Load model
    model_path = os.environ.get('MODEL_PATH', '/opt/ml/model')
    predictor = ThaiOCRPredictor(model_path)
    
    @app.route('/ping', methods=['GET'])
    def ping():
        """Health check endpoint."""
        return jsonify({'status': 'healthy'})
    
    @app.route('/invocations', methods=['POST'])
    def invocations():
        """Inference endpoint."""
        try:
            image_data = request.get_data()
            result = predictor.predict(image_data)
            return jsonify(result)
        except Exception as e:
            return jsonify({'error': str(e)}), 500
    
    app.run(host='0.0.0.0', port=8080)
```

## Lambda Orchestration

### Training Orchestrator Lambda
```python
# lambda/training_orchestrator.py
import json
import boto3
import os
import logging
from typing import Dict, Any

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event: Dict[str, Any], context) -> Dict[str, Any]:
    """Orchestrate SageMaker training job."""
    
    sagemaker = boto3.client('sagemaker')
    
    try:
        # Extract parameters from event
        job_name = event.get('job_name', f"thai-ocr-training-{int(time.time())}")
        instance_type = event.get('instance_type', 'ml.p3.2xlarge')
        instance_count = event.get('instance_count', 1)
        
        # Training job configuration
        training_config = {
            'TrainingJobName': job_name,
            'RoleArn': os.environ['SAGEMAKER_ROLE_ARN'],
            'AlgorithmSpecification': {
                'TrainingImage': os.environ['ECR_REPOSITORY'],
                'TrainingInputMode': 'File'
            },
            'InputDataConfig': [
                {
                    'ChannelName': 'training',
                    'DataSource': {
                        'S3DataSource': {
                            'S3DataType': 'S3Prefix',
                            'S3Uri': f"s3://{os.environ['S3_BUCKET']}/training-data/",
                            'S3DataDistributionType': 'FullyReplicated'
                        }
                    },
                    'ContentType': 'application/x-parquet',
                    'CompressionType': 'None'
                }
            ],
            'OutputDataConfig': {
                'S3OutputPath': f"s3://{os.environ['S3_BUCKET']}/model-artifacts/"
            },
            'ResourceConfig': {
                'InstanceType': instance_type,
                'InstanceCount': instance_count,
                'VolumeSizeInGB': 30
            },
            'StoppingCondition': {
                'MaxRuntimeInSeconds': 86400  # 24 hours
            },
            'HyperParameters': {
                'epochs': str(event.get('epochs', 100)),
                'batch-size': str(event.get('batch_size', 32)),
                'learning-rate': str(event.get('learning_rate', 0.001))
            }
        }
        
        # Start training job
        response = sagemaker.create_training_job(**training_config)
        
        logger.info(f"Started training job: {job_name}")
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'Training job started successfully',
                'job_name': job_name,
                'job_arn': response['TrainingJobArn']
            })
        }
        
    except Exception as e:
        logger.error(f"Error starting training job: {e}")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e)
            })
        }
```

## CI/CD Pipeline Configuration

### GitHub Actions Workflow
```yaml
# .github/workflows/deploy.yml
name: Deploy Thai OCR Model

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  AWS_REGION: us-west-2
  ECR_REPOSITORY: thai-ocr
  
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.8'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest
    
    - name: Run tests
      run: pytest tests/
  
  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1
    
    - name: Build and push Docker image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
  
  deploy-infrastructure:
    needs: build-and-push
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
    
    - name: Terraform Init
      run: terraform init
      working-directory: terraform/
    
    - name: Terraform Plan
      run: terraform plan
      working-directory: terraform/
    
    - name: Terraform Apply
      if: github.ref == 'refs/heads/main'
      run: terraform apply -auto-approve
      working-directory: terraform/
```
