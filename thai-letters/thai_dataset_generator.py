#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Optimized Thai Character Dataset Generator
‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÑ‡∏°‡πà‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏à‡∏ô‡∏°‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageEnhance
import json
import random
import argparse
from datetime import datetime

class OptimizedThaiGenerator:
    def __init__(self, output_dir="thai_dataset_production", samples_per_char=10):
        self.output_dir = output_dir
        self.samples_per_char = samples_per_char
        self.image_size = (128, 64)
        
        # ‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡πÅ‡∏•‡∏∞‡∏Ç‡∏ô‡∏≤‡∏î
        self.font_path = self._find_tahoma_font()
        # ‡∏Ç‡∏ô‡∏≤‡∏î font ‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô)
        self.font_sizes = [36, 42, 48, 54, 60, 66, 72]
        
        # ‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡∏•‡∏î‡∏à‡∏≤‡∏Å 15 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 8 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó)
        self.obstacles = {
            # ‡∏Å‡∏≤‡∏£‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (‡∏•‡∏î‡∏•‡∏á)
            'rotation': [-2, -1, 0, 1, 2],
            
            # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á (‡∏•‡∏î‡∏ä‡πà‡∏ß‡∏á)
            'brightness': [0.8, 0.9, 1.0, 1.1, 1.2],
            
            # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏°‡∏ä‡∏±‡∏î (‡∏•‡∏î‡∏ä‡πà‡∏ß‡∏á)
            'contrast': [0.8, 0.9, 1.0, 1.1, 1.2],
            
            # ‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏•‡∏≠‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (‡∏•‡∏î‡∏•‡∏á)
            'blur': [0, 0.2, 0.4],
            
            # ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏ô‡πâ‡∏≠‡∏¢ (‡∏•‡∏î‡∏•‡∏á)
            'noise_level': [0, 0.02, 0.05],
            
            # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏•‡∏≤‡∏á‡πÜ)
            'position': ['center-left', 'center', 'center-right'],
            
            # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á
            'padding': [15, 20, 25],
            
            # ‡∏Å‡∏≤‡∏£‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á)
            'compression': [85, 90, 95, 100]
        }
        
        # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
        self.stats = {
            "total_characters": 0,
            "samples_per_char": samples_per_char,
            "total_generated": 0,
            "successful": 0,
            "failed": 0,
            "obstacles_applied": {},
            "timestamp": datetime.now().isoformat()
        }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, "images"), exist_ok=True)
        
    def _find_tahoma_font(self):
        """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ font ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"""
        # Font paths ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Thai support ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ
        paths = [
            # Windows fonts (via WSL)
            "/mnt/c/Windows/Fonts/tahoma.ttf",
            "/mnt/c/Windows/Fonts/Tahoma.ttf",
            "/mnt/c/Windows/Fonts/THSarabun.ttf",
            "/mnt/c/Windows/Fonts/thsarabun.ttf",
            # Standard Windows paths
            "C:/Windows/Fonts/tahoma.ttf",
            "C:/Windows/Fonts/Tahoma.ttf",
            "C:/Windows/Fonts/THSarabun.ttf",
            # macOS
            "/System/Library/Fonts/Tahoma.ttf",
            "/System/Library/Fonts/Arial Unicode MS.ttf",
            # Linux system fonts
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
            "/usr/share/fonts/TTF/DejaVuSans.ttf",
            # Thai fonts in Linux
            "/usr/share/fonts/truetype/thai/TlwgMono.ttf",
            "/usr/share/fonts/truetype/thai/Loma.ttf",
            "/usr/share/fonts/truetype/thai/Norasi.ttf",
        ]
        
        for path in paths:
            if os.path.exists(path):
                print(f"üî§ Found font: {path}")
                return path
        
        print("‚ö†Ô∏è No Thai-compatible font found, using default")
        return None
        
    def _load_characters(self, dict_path):
        """‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå"""
        characters = []
        with open(dict_path, 'r', encoding='utf-8') as f:
            for line in f:
                char = line.strip()
                if char and char not in ['', ' ', '\n']:
                    characters.append(char)
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÑ‡∏î‡πâ
        valid_chars = []
        for char in characters:
            if self._can_render_character(char):
                valid_chars.append(char)
        
        print(f"üìñ Valid characters: {len(valid_chars)}/{len(characters)}")
        return valid_chars
        
    def _can_render_character(self, char):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        try:
            test_img = Image.new('RGB', (64, 32), (255, 255, 255))
            draw = ImageDraw.Draw(test_img)
            
            if self.font_path:
                font = ImageFont.truetype(self.font_path, 24)
            else:
                font = ImageFont.load_default()
                
            draw.text((10, 5), char, fill=(0, 0, 0), font=font)
            
            array = np.array(test_img)
            gray = cv2.cvtColor(array, cv2.COLOR_RGB2GRAY)
            return not np.all(gray == 255)
            
        except:
            return False
            
    def _random_obstacles(self):
        """‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÅ‡∏ö‡∏ö‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
        selected = {}
        for obstacle_type, options in self.obstacles.items():
            selected[obstacle_type] = random.choice(options)
            
            # ‡∏ô‡∏±‡∏ö‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ
            if obstacle_type not in self.stats["obstacles_applied"]:
                self.stats["obstacles_applied"][obstacle_type] = {}
            obstacle_value = str(selected[obstacle_type])
            if obstacle_value not in self.stats["obstacles_applied"][obstacle_type]:
                self.stats["obstacles_applied"][obstacle_type][obstacle_value] = 0
            self.stats["obstacles_applied"][obstacle_type][obstacle_value] += 1
            
        return selected
        
    def generate_character_variations(self, char, char_index):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ï‡∏±‡∏ß"""
        variations = []
        
        for sample_idx in range(self.samples_per_char):
            try:
                # ‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ
                obstacles = self._random_obstacles()
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û
                img = self._create_optimized_image(char, obstacles)
                
                if img is not None:
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û
                    filename = f"{char_index:03d}_{sample_idx:02d}.jpg"
                    filepath = os.path.join(self.output_dir, "images", filename)
                    
                    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ö‡∏µ‡∏ö‡∏≠‡∏±‡∏î
                    quality = obstacles['compression']
                    img.save(filepath, 'JPEG', quality=quality)
                    
                    variations.append({
                        "filename": filename,
                        "character": char,
                        "sample_index": sample_idx,
                        "obstacles": obstacles
                    })
                    
                    self.stats["successful"] += 1
                else:
                    self.stats["failed"] += 1
                    
            except Exception as e:
                print(f"‚ùå Error creating variation {sample_idx} for '{char}': {e}")
                self.stats["failed"] += 1
                
        return variations
        
    def _create_optimized_image(self, char, obstacles):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ"""
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß
            img = Image.new('RGB', self.image_size, (255, 255, 255))
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå
            font_size = random.choice(self.font_sizes)
            if self.font_path:
                font = ImageFont.truetype(self.font_path, font_size)
            else:
                font = ImageFont.load_default()
                
            draw = ImageDraw.Draw(img)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
            bbox = draw.textbbox((0, 0), char, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á
            padding = obstacles['padding']
            position = obstacles['position']
            
            if 'left' in position:
                x = padding
            elif 'right' in position:
                x = self.image_size[0] - text_width - padding
            else:  # center
                x = (self.image_size[0] - text_width) // 2
                
            y = (self.image_size[1] - text_height) // 2
            
            # ‡∏ß‡∏≤‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
            draw.text((x, y), char, fill=(0, 0, 0), font=font)
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á
            img_array = np.array(img)
            
            # ‡πÉ‡∏ä‡πâ transformation ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
            img_array = self._apply_gentle_transformations(img_array, obstacles)
            
            # ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô PIL Image
            img = Image.fromarray(img_array)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
            if self._is_image_valid(img):
                return img
            else:
                return None
                
        except Exception as e:
            print(f"Error creating optimized image: {e}")
            return None
            
    def _apply_gentle_transformations(self, img_array, obstacles):
        """‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô ‡πÑ‡∏°‡πà‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏à‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ"""
        
        # ‡∏Å‡∏≤‡∏£‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
        if obstacles['rotation'] != 0:
            center = (img_array.shape[1] // 2, img_array.shape[0] // 2)
            matrix = cv2.getRotationMatrix2D(center, obstacles['rotation'], 1.0)
            img_array = cv2.warpAffine(img_array, matrix, (img_array.shape[1], img_array.shape[0]), 
                                     borderValue=(255, 255, 255))
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á (‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô)
        if obstacles['brightness'] != 1.0:
            img_array = img_array.astype(np.float32)
            img_array *= obstacles['brightness']
            img_array = np.clip(img_array, 0, 255).astype(np.uint8)
        
        # ‡∏õ‡∏£‡∏±‡∏ö contrast (‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô)
        if obstacles['contrast'] != 1.0:
            img_array = img_array.astype(np.float32)
            img_array = ((img_array - 128) * obstacles['contrast'] + 128)
            img_array = np.clip(img_array, 0, 255).astype(np.uint8)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° noise ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
        if obstacles['noise_level'] > 0:
            noise = np.random.normal(0, obstacles['noise_level'] * 255, img_array.shape)
            img_array = img_array.astype(np.float32) + noise
            img_array = np.clip(img_array, 0, 255).astype(np.uint8)
        
        # ‡πÄ‡∏ö‡∏•‡∏≠‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢
        if obstacles['blur'] > 0:
            kernel_size = int(obstacles['blur'] * 4) + 1
            if kernel_size % 2 == 0:
                kernel_size += 1
            if kernel_size >= 3:  # ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠ kernel ‡πÉ‡∏´‡∏ç‡πà‡∏û‡∏≠
                img_array = cv2.GaussianBlur(img_array, (kernel_size, kernel_size), 0)
        
        return img_array
        
    def _is_image_valid(self, img):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ"""
        img_array = np.array(img)
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß
        non_white_pixels = np.sum(gray < 240)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏¢‡∏±‡∏á‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏î‡πâ (‡πÑ‡∏°‡πà‡πÄ‡∏ö‡∏•‡∏≠‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≤‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ)
        edges = cv2.Canny(gray, 50, 150)
        edge_pixels = np.sum(edges > 0)
        
        return non_white_pixels > 50 and edge_pixels > 20
        
    def generate_optimized_dataset(self, dict_path):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á optimized dataset"""
        print("üöÄ Starting Optimized Thai Dataset Generation")
        print(f"üìÅ Output: {self.output_dir}")
        print(f"üî¢ Samples per character: {self.samples_per_char}")
        print(f"üéØ Optimized obstacles: {len(self.obstacles)} types (reduced from 15)")
        print("=" * 60)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        print("üé® Optimized Obstacles (Character-Friendly):")
        for i, (obstacle_type, options) in enumerate(self.obstacles.items(), 1):
            print(f"  {i:2d}. {obstacle_type}: {len(options)} options")
        print("=" * 60)
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
        characters = self._load_characters(dict_path)
        self.stats["total_characters"] = len(characters)
        self.stats["total_generated"] = len(characters) * self.samples_per_char
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå labels
        labels_file = os.path.join(self.output_dir, "labels.txt")
        all_variations = []
        
        with open(labels_file, 'w', encoding='utf-8') as f:
            for char_idx, char in enumerate(characters):
                print(f"üìù Generating {self.samples_per_char} variations for '{char}' ({char_idx+1}/{len(characters)})")
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö
                variations = self.generate_character_variations(char, char_idx)
                all_variations.extend(variations)
                
                # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô labels
                for var in variations:
                    f.write(f"{var['filename']}\t{var['character']}\n")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                if (char_idx + 1) % 50 == 0:
                    success_rate = (self.stats["successful"] / ((char_idx + 1) * self.samples_per_char) * 100)
                    print(f"‚úÖ Progress: {char_idx+1}/{len(characters)} chars | Success rate: {success_rate:.1f}%")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
        details_file = os.path.join(self.output_dir, "dataset_details.json")
        with open(details_file, 'w', encoding='utf-8') as f:
            json.dump({
                "stats": self.stats,
                "variations": all_variations,
                "configuration": {
                    "samples_per_char": self.samples_per_char,
                    "image_size": self.image_size,
                    "font_sizes": self.font_sizes,
                    "obstacles": self.obstacles,
                    "optimization": "Character-friendly, reduced obstacles"
                }
            }, f, ensure_ascii=False, indent=2)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ
        self._print_summary(characters)
        
    def _print_summary(self, characters):
        """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•"""
        print("\n" + "=" * 60)
        print("üìä OPTIMIZED DATASET SUMMARY")
        print("=" * 60)
        print(f"üî§ Total characters: {len(characters)}")
        print(f"üéØ Samples per character: {self.samples_per_char}")
        print(f"üìä Target total images: {len(characters) * self.samples_per_char}")
        print(f"‚úÖ Successfully generated: {self.stats['successful']}")
        print(f"‚ùå Failed: {self.stats['failed']}")
        print(f"üìà Success rate: {(self.stats['successful']/(len(characters) * self.samples_per_char)*100):.1f}%")
        print(f"üìÅ Output directory: {self.output_dir}")
        print(f"üé® Obstacles: Optimized for readability")
        print(f"üëÅÔ∏è  Character visibility: Enhanced")
        print("=" * 60)

def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö arguments"""
    parser = argparse.ArgumentParser(description='Optimized Thai Character Dataset Generator')
    parser.add_argument('samples', type=int, 
                       help='Number of samples per character (required)')
    parser.add_argument('-d', '--dict', default='th_dict.txt', 
                       help='Path to character dictionary file (default: th_dict.txt)')
    parser.add_argument('-o', '--output', default=None,
                       help='Output directory (default: auto-generated)')
    parser.add_argument('--show-obstacles', action='store_true',
                       help='Show optimized obstacles and exit')
    
    args = parser.parse_args()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    if args.show_obstacles:
        generator = OptimizedThaiGenerator()
        print("üé® Optimized Obstacles (Character-Friendly):")
        for i, (obstacle_type, options) in enumerate(generator.obstacles.items(), 1):
            print(f"{i:2d}. {obstacle_type}:")
            print(f"    Options: {options}")
            print()
        return
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠ output directory ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
    if args.output is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        dataset_name = f"thai_dataset_{args.samples}samples_{timestamp}"
        # ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô datasets/raw/ directory (default ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
        os.makedirs("datasets/raw", exist_ok=True)
        args.output = f"datasets/raw/{dataset_name}"
    # ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏∏ output path ‡∏°‡∏≤‡πÄ‡∏≠‡∏á ‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏ô‡∏±‡πâ‡∏ô
    
    print(f"üéØ Creating optimized dataset: {args.samples} samples per character")
    print(f"üìñ Dictionary: {args.dict}")
    print(f"üìÅ Output: {args.output}")
    print(f"üëÅÔ∏è  Optimization: Character visibility enhanced")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á generator
    generator = OptimizedThaiGenerator(args.output, args.samples)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset
    generator.generate_optimized_dataset(args.dict)
    
    print(f"\nüéâ Optimized dataset completed!")
    print(f"üìÅ Images: {args.output}/images/")
    print(f"üìÑ Labels: {args.output}/labels.txt")
    print(f"üìã Details: {args.output}/dataset_details.json")

if __name__ == "__main__":
    main()
